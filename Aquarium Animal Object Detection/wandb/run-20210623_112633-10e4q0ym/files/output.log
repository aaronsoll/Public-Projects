
Epoch: [0]  [  0/447]  eta: 0:12:14  lr: 0.000013  loss: 2.0323 (2.0323)  loss_classifier: 1.8938 (1.8938)  loss_box_reg: 0.1004 (0.1004)  loss_objectness: 0.0368 (0.0368)  loss_rpn_box_reg: 0.0014 (0.0014)  time: 1.6439  data: 0.0600  max mem: 1201
Epoch: [0]  [ 25/447]  eta: 0:03:34  lr: 0.000237  loss: 0.7813 (1.2990)  loss_classifier: 0.5832 (1.1405)  loss_box_reg: 0.1515 (0.1412)  loss_objectness: 0.0069 (0.0136)  loss_rpn_box_reg: 0.0016 (0.0038)  time: 0.4582  data: 0.0337  max mem: 1633
Traceback (most recent call last):
  File "c:/Users/aaron/OneDrive/Documents/PERSONAL DOCUMENTS/Private-Projects/Learning ML/Aquarium Classify/test_completed_model.py", line 1, in <module>
    from aquarium_model import NUM_CLASSES
  File "c:\Users\aaron\OneDrive\Documents\PERSONAL DOCUMENTS\Private-Projects\Learning ML\Aquarium Classify\aquarium_model.py", line 71, in <module>
    train_one_epoch(model, optimizer, data_loader,
  File "c:\Users\aaron\OneDrive\Documents\PERSONAL DOCUMENTS\Private-Projects\Learning ML\Aquarium Classify\engine.py", line 34, in train_one_epoch
    loss_dict = model(images, targets)
  File "C:\Users\aaron\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\aaron\anaconda3\lib\site-packages\torchvision\models\detection\generalized_rcnn.py", line 97, in forward
    proposals, proposal_losses = self.rpn(images, features, targets)
  File "C:\Users\aaron\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\aaron\anaconda3\lib\site-packages\torchvision\models\detection\rpn.py", line 345, in forward
    anchors = self.anchor_generator(images, features)
  File "C:\Users\aaron\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\aaron\anaconda3\lib\site-packages\torchvision\models\detection\anchor_utils.py", line 147, in forward
    strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),
  File "C:\Users\aaron\anaconda3\lib\site-packages\torchvision\models\detection\anchor_utils.py", line 147, in <listcomp>
    strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),
KeyboardInterrupt